{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q6raY-U6Pv0",
        "outputId": "b9bdffe8-f099-4adb-b54a-7b8e5f609423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = \"https://raw.githubusercontent.com/NVDLI/LDL/main/pt_framework/utilities.py\" \n",
        "r=requests.get(url) \n",
        "with open('utilities.py', 'w') as f: \n",
        "  f.write(r.text)"
      ],
      "metadata": {
        "id": "DqfZfBOM657S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision. transforms as transforms\n",
        "from torchvision.datasets import CIFAR10 \n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from utilities import train_model\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "BATCH_SIZE=32\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms. ToTensor()]) \n",
        "trainset=CIFAR10(root=\"./pt_data\", train=True, download=True, transform=transform) \n",
        "trainloader=DataLoader(trainset, batch_size=len(trainset), shuffle=False) \n",
        "data=next(iter (trainloader))\n",
        "\n",
        "mean = data[0].mean()\n",
        "\n",
        "stddev = data[0].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo5TN9kP7x0S",
        "outputId": "41177fd3-e8c0-4210-bfd9-f667a07c287d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We imported the data and imported all the needed liberies for the data. We gave epoch size and batch size. We downloaded the data from the torch libary wth the help of dataloader."
      ],
      "metadata": {
        "id": "WKKHIK7YSDgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose( \n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean,stddev)])\n",
        "\n",
        "trainset = CIFAR10(root='./pt_data', train=True, download=True,transform=transform) \n",
        "testset = CIFAR10(root='./pt_data', train=False, download=True,transform=transform)\n",
        "\n",
        "\n",
        "model = nn. Sequential(\n",
        "    nn.Conv2d(3, 64, 5, stride=2, padding=2),\n",
        "    nn.ReLU(),\n",
        "    nn. Conv2d(64, 64, 3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear (64*8*8, 10)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYCPtdrJ9E_4",
        "outputId": "58372063-8e68-484a-9c59-d1a1e7c22958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we defined what are the test and train data. We got CIFAR10. Then we added Convolutional layers, 3 by 3 size karnel, with 2 padding. So behind it, there is a multiplication with 3 b3 size matrix. Then activation was ReLu. Then we flattened all as a list to male a model."
      ],
      "metadata": {
        "id": "rPEU-7XoSXwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layers = next (model.modules())\n",
        "conv_layer0=layers[0]\n",
        "\n",
        "conv_layer1=layers[2]\n",
        "\n",
        "output_layer=layers[5]\n",
        "\n",
        "\n",
        "nn.init.kaiming_normal_(conv_layer0.weight)\n",
        "\n",
        "nn.init.constant(conv_layer0.bias,0.0)\n",
        "\n",
        "nn.init.kaiming_normal_(conv_layer1.weight)\n",
        "\n",
        "nn.init.constant (conv_layer1.bias, 0.0)\n",
        "\n",
        "nn. init.xavier_uniform (output_layer.weight)\n",
        "\n",
        "nn.init.constant (output_layer.bias, 0.0)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters()) \n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "train_model(model, device, EPOCHS, BATCH_SIZE, trainset, testset, optimizer, loss_function, 'acc')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A4EkPPZ-leD",
        "outputId": "bd7bebfd-5024-4a8e-bcf1-c790ec33107c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 loss: 1.4115 - acc: 0.5003 - val_loss: 1.2192 - val_acc: 0.5659\n",
            "Epoch 2/30 loss: 1.0736 - acc: 0.6258 - val_loss: 1.0885 - val_acc: 0.6196\n",
            "Epoch 3/30 loss: 0.9316 - acc: 0.6753 - val_loss: 1.0566 - val_acc: 0.6343\n",
            "Epoch 4/30 loss: 0.8332 - acc: 0.7091 - val_loss: 1.0670 - val_acc: 0.6392\n",
            "Epoch 5/30 loss: 0.7520 - acc: 0.7395 - val_loss: 1.0460 - val_acc: 0.6474\n",
            "Epoch 6/30 loss: 0.6828 - acc: 0.7614 - val_loss: 1.0842 - val_acc: 0.6460\n",
            "Epoch 7/30 loss: 0.6208 - acc: 0.7822 - val_loss: 1.1176 - val_acc: 0.6424\n",
            "Epoch 8/30 loss: 0.5665 - acc: 0.7992 - val_loss: 1.1783 - val_acc: 0.6422\n",
            "Epoch 9/30 loss: 0.5204 - acc: 0.8170 - val_loss: 1.2223 - val_acc: 0.6497\n",
            "Epoch 10/30 loss: 0.4743 - acc: 0.8307 - val_loss: 1.3527 - val_acc: 0.6297\n",
            "Epoch 11/30 loss: 0.4359 - acc: 0.8448 - val_loss: 1.3891 - val_acc: 0.6364\n",
            "Epoch 12/30 loss: 0.4030 - acc: 0.8551 - val_loss: 1.4974 - val_acc: 0.6319\n",
            "Epoch 13/30 loss: 0.3743 - acc: 0.8661 - val_loss: 1.5685 - val_acc: 0.6318\n",
            "Epoch 14/30 loss: 0.3451 - acc: 0.8763 - val_loss: 1.6695 - val_acc: 0.6291\n",
            "Epoch 15/30 loss: 0.3205 - acc: 0.8833 - val_loss: 1.7489 - val_acc: 0.6301\n",
            "Epoch 16/30 loss: 0.2967 - acc: 0.8939 - val_loss: 1.8392 - val_acc: 0.6244\n",
            "Epoch 17/30 loss: 0.2800 - acc: 0.8971 - val_loss: 2.0382 - val_acc: 0.6208\n",
            "Epoch 18/30 loss: 0.2634 - acc: 0.9050 - val_loss: 2.0063 - val_acc: 0.6242\n",
            "Epoch 19/30 loss: 0.2474 - acc: 0.9116 - val_loss: 2.1842 - val_acc: 0.6184\n",
            "Epoch 20/30 loss: 0.2387 - acc: 0.9139 - val_loss: 2.2794 - val_acc: 0.6164\n",
            "Epoch 21/30 loss: 0.2195 - acc: 0.9205 - val_loss: 2.4347 - val_acc: 0.6152\n",
            "Epoch 22/30 loss: 0.2083 - acc: 0.9229 - val_loss: 2.4376 - val_acc: 0.6071\n",
            "Epoch 23/30 loss: 0.2117 - acc: 0.9226 - val_loss: 2.5441 - val_acc: 0.6169\n",
            "Epoch 24/30 loss: 0.1944 - acc: 0.9296 - val_loss: 2.7032 - val_acc: 0.6099\n",
            "Epoch 25/30 loss: 0.1917 - acc: 0.9310 - val_loss: 2.7599 - val_acc: 0.6164\n",
            "Epoch 26/30 loss: 0.1781 - acc: 0.9360 - val_loss: 2.8841 - val_acc: 0.6126\n",
            "Epoch 27/30 loss: 0.1772 - acc: 0.9365 - val_loss: 2.9249 - val_acc: 0.6146\n",
            "Epoch 28/30 loss: 0.1711 - acc: 0.9385 - val_loss: 3.0027 - val_acc: 0.6107\n",
            "Epoch 29/30 loss: 0.1666 - acc: 0.9406 - val_loss: 3.2499 - val_acc: 0.6079\n",
            "Epoch 30/30 loss: 0.1639 - acc: 0.9419 - val_loss: 3.3154 - val_acc: 0.6074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9419385796545106, 0.6074281150159745]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next process is training. In order to train the model we have to give weights. So each weight is added before giving to the train."
      ],
      "metadata": {
        "id": "_ALZ9IWUTBge"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W125r4xP-Joj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}